# ğŸŒ¿ TarÄ±m Chatbot

Bu proje, Teknofest 2025 TÃ¼rkÃ§e DoÄŸal Dil Ä°ÅŸleme YarÄ±ÅŸmasÄ± Serbest Kategori iÃ§in geliÅŸtirilmiÅŸtir. TÃ¼rkÃ§e tarÄ±m sorularÄ±na cevap veren basit bir yapay zeka destekli chatbot prototipidir.

## Ã–zellikler

## Kurulum
```bash

Bu repo, **Gradio tabanlÄ± bir frontend** ve **FastAPI tabanlÄ± bir backend** iÃ§erir.  
AmaÃ§: Metin/ses ile LLMâ€™e danÄ±ÅŸmak ve gÃ¶rselleri (Ã¶r. bitki hastalÄ±ÄŸÄ±/Ã¼rÃ¼n sÄ±nÄ±fÄ±) **MobileNetV3** ile sÄ±nÄ±flandÄ±rmak.  
Ses (STT) Ã¶zelliÄŸi **opsiyoneldir** ve `faster-whisper` ile saÄŸlanÄ±r.

> **KÄ±sa Ã–zet**
> - Frontend: `tddi_frontend.py` â†’ Gradio arayÃ¼zÃ¼ (Sohbet + GÃ¶rsel yÃ¼kleme + Mikrofon)
> - Backend:  `tddi_backend.py` â†’ FastAPI (LLM + MobileNetV3 gÃ¶rÃ¼ntÃ¼ sÄ±nÄ±flandÄ±rma + opsiyonel STT)
> - VarsayÄ±lan LLM: `Qwen/Qwen2.5-3B-Instruct`
> - GÃ¶rÃ¼ntÃ¼ modeli: MobileNetV3-Small (Ã¶zel aÄŸÄ±rlÄ±k dosyasÄ± gerekir)
> - STT: `faster-whisper` (FFmpeg kurulu olmalÄ±; **opsiyonel**)

---

## ğŸ¯ Ã–zellikler

- **Sohbet (LLM):** `/chat` uÃ§ noktasÄ± ile mesaj geÃ§miÅŸi destekli yanÄ±t Ã¼retimi
- **GÃ¶rÃ¼ntÃ¼ sÄ±nÄ±flandÄ±rma:** `/predict` ile **Topâ€‘k** tahmin (etiket + skor)
- **Sesle sohbet (opsiyonel):**
  - `/transcribe`: Sesi yazÄ±ya Ã§evirme (TR destekli)
  - `/chat_from_audio`: Sesi yazÄ±ya Ã§evirir ve LLM yanÄ±tÄ± dÃ¶ndÃ¼rÃ¼r
- **HazÄ±rlÄ±k/saÄŸlÄ±k kontrolleri:** `/health`, `/ready`, `/routes`

---



> Not: DosyalarÄ±nÄ±z ÅŸu an kÃ¶k dizinde olabilir; bu sadece Ã¶neri.

---

## ğŸ§© BaÄŸÄ±mlÄ±lÄ±klar

- Python 3.9â€“3.11 Ã¶nerilir
- PyTorch (CPU/GPU): Kendi CUDA sÃ¼rÃ¼mÃ¼nÃ¼ze uygun tekeri kurmanÄ±z gerekebilir
- FFmpeg (opsiyonel, STT iÃ§in Ã¶nerilir)

Kurulum (sanal ortam ile):
```bash
python -m venv .venv
# Windows
.venv\\Scripts\\activate
# macOS/Linux
source .venv/bin/activate

pip install -r requirements.txt
```

> **PyTorch (GPU) iÃ§in:** CUDA sÃ¼rÃ¼mÃ¼nÃ¼ze uygun teker komutunu PyTorchâ€™un resmi yÃ¶nergelerinden uygulayÄ±n; ardÄ±ndan `torch` ve `torchvision` doÄŸru kurulmuÅŸ olmalÄ±.

---

## ğŸš€ Ã‡alÄ±ÅŸtÄ±rma

### 1) Backendâ€™i baÅŸlatÄ±n
Ã–nce **model dosyalarÄ±nÄ±zÄ±** hazÄ±rlayÄ±n:
- `models/mobilenetv3_small_plants_best.pt`
- `models/labels.txt` (satÄ±r baÅŸÄ±na 1 sÄ±nÄ±f adÄ±)

ArdÄ±ndan Ã¶rnek komut:
```bash
# (opsiyonel) Windows PowerShell:
# $env:MODEL_PATH=".\\models\\mobilenetv3_small_plants_best.pt"; $env:LABELS_PATH=".\\labels.txt"

# (macOS/Linux)
export MODEL_PATH=./models/mobilenetv3_small_plants_best.pt
export LABELS_PATH=./labels.txt

uvicorn tddi_backend:app --host 0.0.0.0 --port 8000 --reload
```

### 2) Frontendâ€™i baÅŸlatÄ±n
```bash
# Backend URLâ€™ini belirtin
# (Windows) $env:BACKEND_URL="http://127.0.0.1:8000"
# (macOS/Linux) export BACKEND_URL=http://127.0.0.1:8000

python tddi_frontend.py
```
ArayÃ¼z varsayÄ±lan olarak `http://127.0.0.1:7860` Ã¼zerinde aÃ§Ä±lÄ±r.

---

## ğŸ§ª API HÄ±zlÄ± Test

**GÃ¶rÃ¼ntÃ¼ SÄ±nÄ±flandÄ±rma**
```bash
curl -F "file=@test.jpg" http://127.0.0.1:8000/predict
```

**Sohbet (LLM)**
```bash
curl -X POST http://127.0.0.1:8000/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Merhaba!", "history": []}'
```

**Transkripsiyon (STT, opsiyonel)**
```bash
curl -X POST http://127.0.0.1:8000/transcribe \
  -F "file=@recording.wav"
```

**Sesten Sohbet (STT + LLM, opsiyonel)**
```bash
curl -X POST http://127.0.0.1:8000/chat_from_audio \
  -F "file=@recording.wav"
```

---

## ğŸ”§ Sorun Giderme

- **`503 STT devre dÄ±ÅŸÄ±` hatasÄ±**: `faster-whisper` kurulmamÄ±ÅŸ olabilir veya FFmpeg yoktur. FFmpegâ€™i PATHâ€™e ekleyin ve `pip install faster-whisper` kurulu olduÄŸundan emin olun.
- **`MODEL_PATH bulunamadÄ±`**: AÄŸÄ±rlÄ±k dosyasÄ± yolunu doÄŸru verin (`MODEL_PATH`).
- **CUDA/HafÄ±za sorunlarÄ±**: LLM iÃ§in `LLM_MAX_NEW` dÃ¼ÅŸÃ¼rÃ¼n, gerekirse CPUâ€™da Ã§alÄ±ÅŸtÄ±rÄ±n (`device_map=None` varsayÄ±lan olarak CPUâ€™yu kullanÄ±r). GÃ¶rÃ¼ntÃ¼ modeli iÃ§in `DEVICE=cpu` ayarlayabilirsiniz.
- **CORS (gÃ¼venlik)**: Ã–rnek uygulamada `allow_origins=["*"]`. Ãœretimde daraltmanÄ±z Ã¶nerilir.

---


## ğŸ™ TeÅŸekkÃ¼r

